# 八股文-3

### 30.map相关

#### 什么类型可以作为map 的key？

**在Go语言中，map的key可以是任何可以比较的类型。**

可比较类型，包括：

- **整数**：如 `int`, `int8`, `int16`, `int32`, `int64`, `uint`, `uint8`, `uint16`, `uint32`, `uint64`, `uintptr`
- **浮点数**：如 `float32`, `float64`
- **字符串**：`string`
- **布尔值**：`bool`

- **结构体**：只要结构体的所有字段都是可比较的类型。
- **数组**：数组的元素类型必须是可比较的。

不可比较类型，不能作为key：

- **切片**：`slice`
- **映射**：`map`
- **函数**：`function`

**处理不可比较类型：**如果你需要使用切片、映射或函数作为键，可以考虑以下方法：

- **使用指针**：将切片或其他不可比较类型的指针作为键。
- **封装在结构体中**：将不可比较类型封装在一个可比较的结构体中，并确保结构体的字段都是可比较的。





#### map 使用注意的点，是否并发安全？

**map注意点：**

1. **key 唯一**：map 中 key 不允许重复，重复赋值会覆盖旧值。
2. **key 可比较**：key 必须是支持“==”比较的类型，如字符串、整数、结构体（不含 slice、map、func）。
3. **nil map 不能写**：未初始化的 map 为 nil，读操作 ok，写操作会 panic，使用前需 `make`。
4. **遍历无序**：Go map 的遍历顺序是随机的，不能依赖顺序处理。
5. **delete 不存在的 key 安全**：`delete(m, k)` 即使 k 不存在也不会 panic。
6. **长度不变**：map 的 `len(m)` 是动态变化的，不能在遍历中安全地删除或添加元素

7. **Go 中原生 map 是非并发安全的！🚫**

> 多个 goroutine 并发读写一个普通 map，会触发 runtime 报错或造成数据不一致。
>
> （map的读和写操作，同时进行，造成bug）



**如何实现map并发安全：**

| 方法           | 适用场景               | 特点                                                 |
| -------------- | ---------------------- | ---------------------------------------------------- |
| `sync.Mutex`   | 读写比例相近           | 手动加锁，简单直接，控制粒度高                       |
| `sync.RWMutex` | 读多写少               | 读写分离，多个读可并发，写互斥                       |
| `sync.Map`     | 高并发、结构简单的共享 | 内部已实现并发安全，使用方式特殊（无索引、无 range） |

使用锁：

```go
var mu sync.RWMutex
m := make(map[string]string)

go func() {
    mu.Lock()
    m["a"] = "1"
    mu.Unlock()
}()

go func() {
    mu.RLock()
    fmt.Println(m["a"])
    mu.RUnlock()
}()
```

如果使用 `sync.Map`：

```go
var sm sync.Map
sm.Store("a", "1")

val, ok := sm.Load("a")
```

> - ❗ **不要在没有加锁的情况下对普通 map 进行 delete 操作**，否则可能引起 panic 或数据竞态。





#### map 循环是有序的还是无序的？

 结论：**无序！每次遍历顺序都可能不同**

- Go 语言中的 `map` 底层是**哈希表（hash table）**，本身就是**无序结构**。
- **每次 `for range map` 的顺序可能不同**，不能依赖其遍历顺序来做业务逻辑。
- Go 的官方文档明确指出：**遍历顺序不是随机的，但也不是固定的**，目的是防止开发者依赖顺序。

**如何实现有序遍历：**

```go
m := map[string]int{
    "banana": 3,
    "apple":  2,
    "pear":   4,
}

// 提取 key 并排序
keys := make([]string, 0, len(m))
for k := range m {
    keys = append(keys, k)
}
sort.Strings(keys)  // 可自定义排序规则

// 按照排序后的 key 遍历
for _, k := range keys {
    fmt.Println(k, m[k])
}
```



#### map 中删除一个 key，它的内存会释放么？

**结论：会释放，但不是立即，也不是全部释放**

> 总结：「delete 清除逻辑键值，是否释放由 GC 决定，map 结构不会缩小，空间优化需另建 map。」

1️⃣ `delete(m, key)` 的实际动作

- 删除的是**逻辑层面的 key-value 对**；

- 被删除的 `key` 和 `value` 不再被 `map` 引用；

  但它们的内存 **是否真正被释放**，还取决于是否被其他地方引用 + 垃圾回收是否执行。

------

2️⃣ 垃圾回收机制的参与

- 如果该 key/value 没有被其他变量引用，**就成了“垃圾”**；

- Go 的垃圾回收器（GC）会在合适时机标记并清理它；

  ❗ **这个回收过程是“延迟发生的”，并不会立刻释放内存**。

------

3️⃣ map 本身的空间是否缩小？

- **不会！map 的底层结构（哈希桶等）不会因此变小**；

- 删除只是“清空槽位”，桶还保留着；

- 多次删除后，map 的容量可能仍旧很大（内存占用高）；

  如果真的需要释放 map 占用的大量空间，可采用以下技巧 👇：

```go
// map 彻底清空释放内存的惯用法：
oldMap := map[string]string{...}
newMap := make(map[string]string)
for k, v := range oldMap {
    if needKeep(k, v) {
        newMap[k] = v
    }
}
// 让 oldMap 被回收
oldMap = nil
```

------

4️⃣ 并发安全问题（重点提示）

- Go 的 map 在并发场景下**不是线程安全的**；

- 如果多个 goroutine 同时访问（读或删），需要用 `sync.Mutex` 或 `sync.Map`；

  ❗**不要在没有加锁的情况下对普通 map 进行 delete 操作**，否则可能引起 panic 或数据竞态。



#### 处理对 map 进行并发访问？ 区别是什么？

| 方案                 | 并发安全             | 适用场景               | 优点                       | 缺点                                 |
| -------------------- | -------------------- | ---------------------- | -------------------------- | ------------------------------------ |
| `sync.Mutex` + map   | ✅（需手动加锁）      | 写多读少、简单控制     | 实现简单，适用于所有操作   | 锁粒度大，所有访问都串行化           |
| `sync.RWMutex` + map | ✅（需手动加读/写锁） | 读多写少               | 支持并发读，读性能较好     | 写操作仍然需要阻塞所有读写           |
| `sync.Map`           | ✅（自动并发安全）    | 高并发读、配置表缓存等 | 内置并发安全结构，无需加锁 | 接口不同于原生 map，写入多时性能下降 |

✅ `sync.Mutex`

```go
var mu sync.Mutex
mu.Lock()
m[key] = val
mu.Unlock()
```

- **适合场景：** 写入频繁、操作简单、数据量小。

✅ `sync.RWMutex`

```go
var rw sync.RWMutex
rw.RLock()
v := m[key]  // 写操作，RLock RUnlock 加解锁
rw.RUnlock()

rw.Lock()
m[key] = val // 读操作,Lock nlock 
rw.Unlock()
```

- **适合场景：** 读操作频繁、写入较少，如配置表、缓存等。

✅ `sync.Map`

```go
var m sync.Map
m.Store("key", 123) //Store 创建key-value
val, ok := m.Load("key") //Load 读key-value
m.Delete("key") //Delete 删除key-value
```

- **适合场景：** 极高并发下的数据共享，如缓存、只增不删的统计等。

> 如果你有 **非常多的并发读写且写入不能少** 的情况，比如亿级别数据并发访问，可以使用：
>
> -  [分段锁 map](https://github.com/orcaman/concurrent-map)：把 map 分成多个小段，每段有自己的锁，减少冲突。
> - 或使用高性能第三方库如：
>   - [`cmap`（concurrent-map）](https://github.com/orcaman/concurrent-map)
>   - [`github.com/puzpuzpuz/xsync`](https://github.com/puzpuzpuz/xsync)（极高性能）

**一句话总结：**

**"写多用 Mutex，读多用 RWMutex，懒人就用 sync.Map，极端并发分段搞定！"**



#### nil map 和空 map 有何不同？

 一、**定义区别**

| map类型     | 定义方式                    | 是否初始化            | 是否可用                 | 内存开销                                 |
| ----------- | --------------------------- | --------------------- | ------------------------ | ---------------------------------------- |
| **nil map** | `var m map[string]int`      | ❌ 没有初始化(零值nil) | 🚫 不能添加元素，会 panic | 零值状态，不占内存（底层结构没建立）     |
| **空 map**  | `m := make(map[string]int)` | ✅ 已初始化            | ✅ 可正常使用             | 没有元素，但底层结构已分配，占用少量内存 |

------

🧠 二、**操作行为对比**

| 操作     | nil map                                                | 空 map                         |
| -------- | ------------------------------------------------------ | ------------------------------ |
| **插入** | ❌ panic：因为底层没有分配哈希结构                      | ✅ 安全，正常插入               |
| **查找** | ✅ 安全，返回零值（如 0、""、false）                    | ✅ 安全，返回零值               |
| **删除** | ⛔️ 某些老版本会 panic（Go 1.12 前），新版本安全但无效果 | ✅ 安全，删除不存在键也不会出错 |

> - 可通过 `if m == nil` 判断是否为 nil map。
> - 想避免 nil map 的 panic？那就总是用 `make()` 创建再使用吧



#### map 的数据结构是什么？ 

答：

##### 底层结构：

golang 中 map 是一个 kv 对集合。**每个 map 的底层结构是 hmap，是有若干个结构为 bmap 的 bucket 组成的数组。每个 bucket 底层都采用链表结构。**

> 1. **Go 的 map 在底层是通过一个叫做 `hmap` 的结构体来实现的。**
>
> ```go
> type hmap struct {
>     count     int            // 当前map中元素的数量
>     flags     uint8          // 一些标志位
>     B         uint8          // bucket 的数量是 2^B 	  !!!
>     noverflow uint16         // 溢出 bucket 的数量 	      !!!
>     hash0     uint32         // 哈希种子，用于 hash 函数
>     buckets    unsafe.Pointer // 指向 buckets 数组         !!!
>     oldbuckets unsafe.Pointer // 旧的 buckets，扩容时用到    !!!
>     nevacuate  uintptr        // 扩容迁移进度
>     extra      *mapextra      // 存储扩容相关的额外信息
> }
> ```
>
> - `buckets` 是一个数组，里面的元素是 **bucket（桶）**。
> - 每个 bucket 又是多个 `key-value` 的容器。
>
> 2. **每个 bucket 的结构：bmap**
>
> ```go
> type bmap struct {
>     tophash  [8]uint8 // 哈希值高位的前8位，用于快速判断键是否可能相等
>     data     byte[1]  // 实际存储 key 和 value 的数据区域（伪代码）
>     overflow *bmap    // 如果一个 bucket 放不下，会指向下一个 bucket（溢出桶）
> }
> ```
>
> 底层使用 hash table，用链表来解决冲突 ，出现冲突时，不是每一个 key 都申请一个结构通过链表串起来，而是以 bmap 为最小粒度挂载，一个 bmap 可以放 8 个 kv。在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。

#### **解决哈希冲突：**

##### **什么是哈希冲突？**

当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用**链地址法**来解决键冲突。
由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。
下图展示产生冲突后的map：
![img](https://camo.githubusercontent.com/e4dbbca35605c61c419b9f61543c508888ce6191f354483d276cc5a8c8212cfb/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032322f706e672f32323231393438332f313636313738393930303838362d61373738333862652d343663382d343235342d393939622d6236653231373732316662662e706e6723617665726167654875653d25323333333333333326636c69656e7449643d7565663463336237612d306265642d34266572726f724d6573736167653d756e6b6e6f776e2532306572726f722666726f6d3d70617374652669643d753738633430613338266f726967696e4865696768743d343430266f726967696e57696474683d373934266f726967696e616c547970653d75726c26726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d3337333335267374617475733d6572726f72267374796c653d6e6f6e65267461736b49643d7561383634643762332d373638332d346234382d393665352d3762326137343339383664267469746c653d)
bucket数据结构指示下一个bucket的指针称为overflow bucket，意为当前bucket盛不下而溢出的部分。

##### **链地址法：**

将所有哈希地址相同的记录都链接在同一链表中。

- 当两个不同的键通过哈希函数计算得到相同的哈希值时，Go的map并不直接覆盖旧的值，而是将这些具有相同哈希值的键值对存储在同一个桶（bucket）中的链表中。这样，即使哈希值相同，也可以通过遍历链表来找到对应的键值对。
- 当桶中的链表长度超过一定阈值时（通常是8个元素），Go的map会进行扩容和重新哈希，以减少哈希冲突，并优化查找、插入和删除操作的性能。

##### 负载因子

负载因子用于衡量一个哈希表冲突情况，公式为：

> 负载因子 = 键数量/bucket数量

例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1.
哈希表需要将负载因子控制在合适的大小，超过其阀值需要**进行rehash，也即键值对重新组织**：

- 哈希因子过小，说明空间利用率低
- 哈希因子过大，说明冲突严重，存取效率低

每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而**Go则在在负载因子达到6.5时才会触发rehash**，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。



#### map是怎么实现扩容？ 

##### map 的容量大小：

> 负载因子 > 6.5,哈希表的键值对会重新组织（触发了：map扩容）

底层调用 makemap 函数，计算得到合适的 B，**map 容量最多可容纳 $6.5*B$ 个元素**

##### 扩容触发条件：

1. 负载因子 > 6.5时，也即平均每个bucket存储的键值对达到6.5个。
2. overflow数量 > 2^15时，也即overflow数量超过32768时。

##### 扩容方式：

| 类型     | 目的     | 触发条件            | 效果                     |
| -------- | -------- | ------------------- | ------------------------ |
| 增量扩容 | 增加容量 | 负载因子过高        | 2 倍 buckets 数组        |
| 等量扩容 | 减少溢出 | overflow 多但总数少 | 重排 hash，bucket 数不变 |

> 由于负载因子超过阙值时，采用增量扩容

**增量扩容：**

当负载因子过大时，就新建一个bucket，新的bucket长度是原来的2倍，然后旧bucket数据搬迁到新的bucket。
考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，Go采用**逐步搬迁策略**，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。

**搬迁步骤：**

1. 创建新 bucket（容量为原来的 2 倍）

2. 将新数据插入新 bucket

   ![image-20250413200306789](./assets/image-20250413200306789.png)

3. 每次 `map` 操作（查找/插入/删除）时：

   - 搬迁旧 bucket 的 2 个键值对
   - 使用 `nevacuate` 字段记录搬迁进度

4. 所有数据搬完后，释放旧 `oldbuckets`

![image-20250413200450342](./assets/image-20250413200450342.png)



**等量扩容：**

> 触发场景：
>
> - 多次增删 key，导致个别 bucket 积压了很多 overflow
> - 但总键值对数量并不多，负载因子也不高（所以不会触发增量扩容）

所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。

![image-20250413200845952](./assets/image-20250413200845952.png)

**操作流程：**

- 分配新的 buckets（数量不变）
- 重新将原有键值对 hash 一遍，打散分布
- 减少 overflow，提升访问效率



#### 查找过程

查找过程如下：

1. 根据key值算出哈希值
2. **取哈希值低位与hmap.B取模确定bucket位置**
3. **取哈希值高位在tophash数组中查询**
4. 如果tophash[i]中存储值也哈希值相等，则去找到该bucket中的key值进行比较
5. 当前bucket没有找到，则继续**从下个overflow的bucket中查找**。
6. 如果当前处于搬迁过程，则优先从oldbuckets查找

注：如果查找不到，也不会返回空值，而是返回相应类型的0值。

#### 插入过程

新元素插入过程如下：

1. 根据key值算出哈希值
2. 取哈希值低位与hmap.B取模确定bucket位置
3. 查找该key是否已经存在，如果存在则直接更新值
4. 如果没找到将key，将key插入



#### 对map里面的一个元素取地址，可以吗

**看情况：**

| 写法                   | 是否能取地址     | 是否能修改值                  | 安全性         |
| ---------------------- | ---------------- | ----------------------------- | -------------- |
| `m := map[string]int`  | ❌ 不可取地址     | ✅ 可直接改值（`m["a"] = 1`）  | 高（自动管理） |
| `m := map[string]*int` | ✅ 可取地址并修改 | ✅ 可通过 `*m["a"] = ...` 改值 | 需小心指针空值 |

🌟 为什么不能直接对 map 中的元素取地址？

Go 语言不允许像下面这样写：

```go
m := map[string]int{"a": 100}
// 错误 ❌
p := &m["a"] // 编译报错：cannot take the address of m["a"]
```

✅ 原因是：

1. **map 中的值访问本质是复制副本**，不是对“真实值”的直接引用；
2. map 内部的结构 **为了并发安全和动态扩容，元素的内存地址可能随时改变**；
3. 所以 Go 不允许你对 `m[key]` 取地址，避免你拿到了一个不稳定甚至无效的地址。

------

💡 正确做法：让 map 的 value 是一个指针！

这样你就可以通过指针“间接”地修改 map 中的值啦～举个可爱的小例子：

```go
package main

import "fmt"

func main() {
	m := make(map[string]*int)

	// 初始化值
	v := 100
	m["a"] = &v

	// 取地址并修改
	*m["a"] = 200

	fmt.Println(*m["a"]) // 输出：200
}
```

🧠 这样我们就可以“取到 map 元素的地址”了，因为我们本来就存的是一个地址！



#### sync.map

`sync.Map` 是 Go 语言**标准库中提供的并发安全的 Map 类型**，它**适用于读多写少的场景**。以下是 `sync.Map` 的一些关键原理：

1. **读写分离**：`sync.Map` 通过读写分离来提升性能。它内部**维护了两种数据结构：一个只读的只读字典 (`read`)，一个读写字典 (`dirty`)**。读操作优先访问只读字典，只有在只读字典中找不到数据时才会访问读写字典。

   ```pgsql
   +--------------------+       +--------------------+
   |   read-only map    |       |    dirty map       |
   |    (read)          |       | (读写 & 写入更新)  |
   | 快速 & 无锁读取 ✅   | <---- | 慢速 & 需要加锁 🔐  |
   +--------------------+       +--------------------+
            ↑                            ↑
          原子访问                     加锁写入
            ↑                            ↑
           Load()       Store()       LoadOrStore() 等操作
   
   ```

   - `Load()` 时，先去 `read` 找；
   - 找不到，就去 `dirty` 找；
   - 若在 `dirty` 中找到了，会触发 “**misses + 1**”；
   - 如果 `misses` 达到阈值，就触发 `read` 与 `dirty` 的同步刷新！

2. **延迟写入**：**写操作并不立即更新只读字典(`read`)，而是更新读写字典 (`dirty`)**。只有在读操作发现只读字典的数据过时（**即 `misses` 计数器超过阈值**）时，才会将读写字典中的数据同步到只读字典。这种策略减少了写操作对读操作的影响。

3. **条目淘汰**：当**一个条目被删除时，它只从读写字典中删除**。只有在下一次数据同步时，该条目才会从只读字典中删除。

   2.3.即懒加载机制：

   - 写操作只改 `dirty`；
   - `read` 不急着同步；
   - 如果读操作频繁 miss，就表示 `read` 过时；
   - `misses`超过阙值，就整体把 `dirty` 复制给 `read`，更新！

4. **原子操作**：读操作大部分是无锁的，因为它们**主要访问只读的 `read` map**，并通过原子操作 (`atomic.Value`) 来保护读操作；写操作会加锁（使用 `sync.Mutex`）保护写操作，以确保对 `dirty` map 的并发安全 ，确保高并发环境下的安全性。

| 操作类型 | 是否加锁 | 说明                           |
| -------- | -------- | ------------------------------ |
| 读取     | ❌ 无锁   | 通过 `atomic.Value` 保证原子性 |
| 写入     | ✅ 加锁   | 使用 `sync.Mutex` 保护 `dirty` |



#### sync.map的锁机制跟你自己用锁加上map有区别么

本质区别（机制）

| 特性             | `sync.Map`                           | `map + 锁`                 |
| ---------------- | ------------------------------------ | -------------------------- |
| **读写分离**     | ✅ 是（read/dirty 分离）              | ❌ 否（需要自己控制锁粒度） |
| **无锁读取**     | ✅ 多数读取是无锁的                   | ❌ 一般读也需要上锁         |
| **写入同步策略** | ✅ **延迟同步**只读区                 | ❌ 手动加锁写入             |
| **数据淘汰策略** | ✅ 有，读写分离导致旧数据**延迟淘汰** | ❌ 自己删除时立即生效       |
| **锁粒度**       | 精细（读无锁、写局部锁）             | 粗粒度（整个 map 加锁）    |

场景及：

| 你场景是          | 推荐使用方式      | 理由                         |
| ----------------- | ----------------- | ---------------------------- |
| 读多写少          | `sync.Map`        | 读无锁、写延迟更新、性能优越 |
| 写多读少          | 普通 `map + 锁`   | sync.Map 写入有额外开销      |
| 读写均衡          | 🟡 看具体实现需求  | 可考虑 `sync.RWMutex + map`  |
| 需要按 key 粒度锁 | `sync.Map` 不适合 | 无法对某个 key 单独加锁      |



#### 按key粒度锁

“**按 key 粒度加锁**”的意思是：

> 在并发访问 map 时，只对特定的某个 key 的操作加锁，而不是整个 map 都加锁。

我们来慢慢讲解一下哈～🌸

------

🌰 举个例子：聊天室在线人数

假设你有一个全局变量 `map[string]int`，用来记录每个房间（room）的在线人数。如果你用的是全局锁，可能会这样写：

```go
var (
    mu     sync.Mutex
    online = make(map[string]int)
)

func EnterRoom(roomID string) {
    mu.Lock()
    online[roomID]++
    mu.Unlock()
}
```

❌ 问题是：即使两个用户进的是不同的房间 `room1`、`room2`，这个 `mu` 也会让他们**串行执行**。

------

✅ 那什么是“按 key 粒度加锁”？

就是让不同 key（如不同房间）的锁互不影响。比如每个 roomID 对应一把锁：

```go
var (
    roomOnline = make(map[string]int)
    roomLocks  = make(map[string]*sync.Mutex)
    globalMu   sync.Mutex // 用来保护 roomLocks
)

func lockFor(roomID string) *sync.Mutex {
    globalMu.Lock()
    defer globalMu.Unlock()
    if l, ok := roomLocks[roomID]; ok {
        return l
    }
    l := &sync.Mutex{}
    roomLocks[roomID] = l
    return l
}

func EnterRoom(roomID string) {
    mu := lockFor(roomID)
    mu.Lock()
    roomOnline[roomID]++
    mu.Unlock()
}
```

🎯 **效果**：

- `room1` 的访问锁是独立的
- `room2` 的访问不会被 `room1` 拖慢
- 写操作不互相阻塞（**高并发性能更好**）

